Ejercicio 1:

A partir del capítulo 26 de AIMA (3er ta edición), se deberá desarrollar un resumen sobre los conceptos más importantes volcados en el capítulo. El mismo deberá contener al menos 2000 palabras y ser escrito utilizando el formato markdown provisto por github **https://github.com.**

**Resumen**

**i. Inteligencia Artificial débil**

La hipótesis de la IA débil se refiere a la afirmación de que es posible que las máquinas actúen con inteligencia, un tema que ha sido objeto de debate filosófico durante décadas, la discusión se centra en la idea de que la inteligencia artificial podría ser imposible, dependiendo de cómo se defina. En términos generales, la IA se describe como la búsqueda del mejor programa agente para una arquitectura dada. Según esta definición, la IA es posible por definición, ya que siempre existirán programas agentes que se pueden enumerar y probar. Sin embargo, los filósofos a menudo se enfocan más en la teoría que en la práctica, lo que deja abierta la cuestión de si la IA puede realmente replicar la inteligencia humana.

Alan Turing, en su artículo "Computing Machinery and Intelligence" (1950), propuso un enfoque diferente para evaluar la inteligencia de las máquinas: el Test de Turing. Este test no pregunta si las máquinas pueden pensar, sino si pueden engañar a un interrogador humano haciéndole creer que está interactuando con otra persona. Si una máquina puede hacer esto al menos el 30% del tiempo, se considera que ha pasado la prueba. Turing también anticipó muchas de las objeciones que se plantearían sobre la posibilidad de máquinas inteligentes, incluidas algunas que aún son relevantes hoy en día.

Una de las objeciones más notables es el "argumento de incapacidad", que sostiene que hay ciertas cosas que una máquina nunca podrá hacer, como por ejemplo ser amable, tener sentido del humor o enamorarse . Sin embargo, desde los años 50, los computadores han demostrado ser capaces de realizar tareas que antes se consideraban exclusivamente humanas, como aprender de la experiencia o tomar decisiones basadas en juicios complejos.

Otro argumento importante es la "objeción matemática", que se basa en el teorema de la incompletitud de Gödel. Este teorema muestra que hay ciertas verdades matemáticas que no pueden ser probadas por sistemas formales concretos, lo que algunos filósofos han interpretado como una limitación fundamental de las máquinas en comparación con los humanos. Sin embargo, el texto argumenta que esta objeción no prueba que los humanos sean superiores, ya que no hay evidencia de que los humanos no están también sujetos a estas limitaciones. 

Finalmente, el texto aborda el "argumento de la informalidad del comportamiento humano", que sugiere que la complejidad del comportamiento humano no puede ser capturada por un conjunto de reglas lógicas simples. Esta crítica se dirige a un enfoque de la IA conocido como GOFAI (Good Old-Fashioned AI), que se basa en la idea de que todo comportamiento inteligente puede ser descrito mediante reglas lógicas. Dreyfus, argumentó que la inteligencia humana implica un conocimiento tácito que no puede ser completamente formalizado en un programa de IA. 

A pesar de sus críticas, Dreyfus también propuso un modelo de adquisición de pericia en cinco etapas, que comienza con un procesamiento basado en reglas y culmina en la capacidad de tomar decisiones de manera intuitiva. Este modelo sugiere que una arquitectura de redes neuronales organizadas en una biblioteca de casos extensa podría abordar algunas de las limitaciones de la IA tradicional. Aunque se han logrado avances en este campo, el texto señala que todavía existen desafíos importantes que no han sido completamente resueltos.

A pesar de los avances significativos, sigue habiendo un debate sobre si las máquinas podrán alguna vez replicar completamente la complejidad y flexibilidad del comportamiento humano.

**ii. Inteligencia Artificial fuerte**

El debate sobre si las máquinas pueden pensar de verdad se centra en la distinción entre simular el pensamiento y tener una verdadera conciencia o mente. Aunque una máquina pase el Test de Turing, muchos filósofos argumentan que esto no significa que esté pensando realmente; sería más bien una simulación del pensamiento. Este punto de vista es lo que Turing denomina el "argumento de la conciencia".

Turing cuestiona la relevancia de este argumento al señalar que, en la vida cotidiana, no tenemos evidencia directa de los estados mentales de otras personas, pero aún así asumimos que piensan. Así que, ¿por qué exigir un estándar más alto para las máquinas? La discusión sobre si las máquinas pueden tener estados mentales reales, como emociones o intenciones, se convierte en una cuestión de convenciones y percepciones, más que en una realidad objetiva.

John Searle, un crítico notable, introduce la analogía de la simulación de una tormenta: una simulación computacional de una tormenta no nos mojará, así como una simulación de procesos mentales no implica necesariamente que haya conciencia real. Su experimento mental de la "Habitación China" refuerza esta idea, mostrando que seguir reglas para manipular símbolos no equivale a entenderlos, lo que sugiere que una máquina podría parecer inteligente sin tener una verdadera comprensión o mente.

Desde un punto de vista teórico, el funcionalismo sugiere que los estados mentales pueden replicarse en cualquier sistema que mantenga la misma estructura causal entre entradas y salidas. Según esta visión, un programa de computadora podría tener los mismos estados mentales que un ser humano si reproduce esos procesos causales. Por su parte, el naturalismo biológico sostiene que los estados mentales dependen de las propiedades específicas de las neuronas, por lo que no cualquier medio físico puede generar los mismos estados mentales, aunque la estructura funcional sea similar.

El problema mente-cuerpo se amplía aquí a un problema "arquitectura-mente", cuestionando si las máquinas pueden tener mentes. Al final, la cuestión sobre si las máquinas pueden pensar realmente sigue siendo abierta, con argumentos fuertes de ambos lados que dependen de cómo entendemos y definimos la mente y la conciencia.

**iii. La ética y los riesgos de desarrollar la inteligencia artificial** 

La discusión sobre la ética y los riesgos en el desarrollo de la inteligencia artificial gira en torno a si se debería continuar avanzando en esta tecnología, considerando los siguientes riesgos potenciales

1\. Las personas podrían perder sus trabajos por automatización: la IA ha automatizado muchos trabajos, lo que ha desplazado a trabajadores humanos. Aunque hasta ahora ha creado más empleos de los que ha eliminado, sigue existiendo la preocupación de que en el futuro, la IA podría reducir drásticamente la necesidad de trabajadores humanos.

2\. Tiempo de ocio: la IA podría llevar a un desequilibrio en el tiempo de ocio, donde algunas personas podrían tener demasiado tiempo libre mientras otras se ven forzadas a trabajar más para mantenerse competitivas en una economía que valora la innovación constante.

3\. Las personas podrían perder el sentido de ser únicos: la posibilidad de que la IA supere la inteligencia humana amenaza el sentido de unicidad de las personas. Si las máquinas pueden realizar tareas intelectuales mejor que los humanos, podría afectar nuestra percepción de lo que significa ser humano.

4\. Pérdida de privacidad: la IA tiene el potencial de aumentar la vigilancia masiva, lo que podría llevar a una pérdida significativa de derechos de privacidad. Este riesgo es particularmente relevante en un mundo donde la seguridad y el control se priorizan sobre las libertades individuales.

5\. Pérdida de responsabilidad: con la creciente dependencia de la IA en áreas críticas como la medicina y las finanzas, surge la pregunta de quién es responsable cuando una IA comete un error. Actualmente, los sistemas se consideran herramientas para apoyar la toma de decisiones humanas, pero en el futuro, podría haber una mayor responsabilidad sobre los sistemas de IA en sí.

6\. El éxito de la Inteligencia Artificial podría significar el fin de la raza humana: el desarrollo de una IA ultrainteligente podría llevar al fin de la raza humana si esta tecnología se vuelve incontrolable. Aunque algunos ven esto como una oportunidad para la evolución de la humanidad hacia una nueva forma de existencia, otros lo consideran una amenaza existencial.

**Discusión**

Una sección de discusión donde se indique una opinión personal sobre los enfoques tratados en el capítulo, su alcance, su viabilidad etc, se debe justificar las opiniones vertidas en esta sección

Cuando hablamos de inteligencia artificial débil nos referimos a la posibilidad de que las máquinas actúen con inteligencia, un tema para el cual a pesar de los avances que se han logrado en el campo de la ia todavía no hay una respuesta concreta, lo que me parece interesante es que  Alan Turing desde 1950 ya venía tratando de darle respuesta a este tema y planteó una lista donde nombra las cosas que no podría hacer una máquina, lo que de una u otra forma establecía ciertos límites en cuanto a la capacidad que se consideraba que podía tener una máquina pero hoy en día vemos como el avance de la inteligencia artificial ha roto con algunos de esos límites que Turing intuía que tendrían las máquinas, en base a esto yo considero que poco a poco se va a ir escalando más sobre lo que puede hacer y no la IA  estableciendo así nuevos límites. Esto por ser la inteligencia artificial un campo que nos permite potenciar nuestras habilidades y representa una oportunidad de desarrollo y crecimiento para los seres humanos. 

Con respecto al tema en que se enfoca la sección de la IA fuerte considero que es muy poco probable que se consiga que las máquinas piensen en el sentido de que tengan una conciencia y que al realizar alguna acción puedan saber lo que están haciendo, creo que hoy en día hay sistemas que pueden simular bien el comportamiento humano pero todo dentro de los límites de lo que se plantea en el texto de la “habitación china”.

Por otro lado, me parece importante que al desarrollar un agente inteligente se debe tener en cuenta los riesgos y los desafíos en términos de seguridad que puede traer el mismo.

Ejercicio 2: 

A partir de la lectura del artículo  [Simulacra as Conscious Exotica](https://arxiv.org/abs/2402.12422) responder:

**1\. ¿Es posible considerar a los agentes conversacionales basados en grandes modelos de lenguaje (LLMs) como conscientes?**

Los LLMs como los agentes conversacionales actuales, generan respuestas basadas en patrones y datos previos sin tener una experiencia subjetiva o autoconciencia. Aunque pueden simular comportamientos que parecen conscientes, esto no significa que realmente lo sean. La conciencia implica una experiencia interna y subjetiva que los LLMs no poseen, estos operan mediante procesamiento de información a gran escala y algoritmos matemáticos, pero carecen de las cualidades fundamentales que generalmente asociamos con la conciencia, como la percepción, el pensamiento reflexivo y el sentimiento. 

**2\. ¿Cuáles son las implicaciones éticas de atribuir conciencia y, por ende, "derechos morales" a los agentes de IA avanzados?** 

Si se considera que un agente de IA es consciente, se abre la posibilidad de que tenga derechos, como el derecho a no ser maltratado o desactivado sin causa justa. Esto podría requerir un replanteamiento de cómo interactuamos con las máquinas y cómo las diseñamos y utilizamos, además existe el riesgo de que, al atribuir conciencia a los LLMs, se pierda de vista que son herramientas creadas y controladas por humanos, lo que podría llevar a una irresponsabilidad moral, donde se descarguen en las máquinas decisiones éticas y sociales que deberían ser humanas.

Ejercicio 3: 

A partir de la lectura del artículo  [You Are Not a Parrot](https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html) elaborar un breve comentario defendiendo el uso de la inteligencia artificial generativa a pesar de los comentarios observados en el artículo.

A pesar de las preocupaciones que se presentan en el artículo, podemos ver como hoy en día la inteligencia artificial ha tenido un impacto positivo para los seres humanos al impulsar la innovación y la productividad liberando así a las personas de tareas rutinarias lo que ha promovido el crecimiento y desarrollo de distintas áreas como tecnología, educación, economía, medicina, entre otras.

